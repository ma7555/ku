{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded keras utilities\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from ku import generators as gr\n",
    "from ku import generic as gen\n",
    "from munch import Munch\n",
    "import pandas as pd, numpy as np\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_params = Munch(batch_size    = 2,\n",
    "                   data_path     = 'images',\n",
    "                   input_shape   = (224,224,3),\n",
    "                   inputs        = ['filename'],\n",
    "                   outputs       = ['score'],\n",
    "                   shuffle       = False,\n",
    "                   fixed_batches = True)\n",
    "\n",
    "ids = pd.read_csv('ids.csv', encoding='latin-1')\n",
    "\n",
    "np.all(ids.columns == ['filename', 'score'])\n",
    "np.all(ids.score == range(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.DataGeneratorDisk(ids, **gen_params)\n",
    "print(isinstance(g[0][1], list))\n",
    "print(np.all(g[0][1][0] == np.array([[1],[2]])))\n",
    "\n",
    "gen.get_sizes(g[0])=='([array<2,224,224,3>], [array<2,1>])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([array<3,1>], <1>, [<1>, <1>])\n",
      "array<1,2>\n",
      "([<1>])\n"
     ]
    }
   ],
   "source": [
    "reload(gen)\n",
    "x = np.array([[1,2,3]])\n",
    "print(gen.get_sizes(([x.T],1,[4,5])))\n",
    "y = np.array([[1,[1,2]]])\n",
    "print(gen.get_sizes(y))\n",
    "z = [g[0],([2],)]\n",
    "print(gen.get_sizes(z[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_params.inputs = ['filename', 'filename']\n",
    "g = gr.DataGeneratorDisk(ids, **gen_params)\n",
    "assert gen.get_sizes(g[0]) == '([array<2,224,224,3>, array<2,224,224,3>], [array<2,1>])'\n",
    "\n",
    "g.inputs_df = ['score', 'score']\n",
    "g.inputs = []\n",
    "g.outputs = []\n",
    "gen.get_sizes(g[0])\n",
    "\n",
    "g.inputs_df = [['score'], ('score','score')]\n",
    "assert gen.get_sizes(g[0]) == '([array<2,1>, array<2,2>], [])'\n",
    "\n",
    "g.inputs_df = []\n",
    "g.outputs = ['score']\n",
    "assert gen.get_sizes(g[0]) == '([], [array<2,1>])'\n",
    "\n",
    "g.outputs = ['score',['score']]\n",
    "with pytest.raises(AssertionError): g[0]\n",
    "\n",
    "g.outputs = [['score'],['score']]\n",
    "assert gen.get_sizes(g[0]) == '([], [array<2,1>, array<2,1>])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gen.H5Helper('data.h5', over_write=True) as h:\n",
    "    data = np.expand_dims(np.array(ids.score), 1)\n",
    "    h.write_data(data, list(ids.filename))\n",
    "\n",
    "with gen.H5Helper('data.h5', 'r') as h:\n",
    "    data = h.read_data(list(ids.filename))\n",
    "    assert all(data == np.array([[1],[2],[3],[4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:        ['filename']\n",
      "fixed_batches: True\n",
      "shuffle:       False\n",
      "outputs:       ['score']\n",
      "data_path:     data.h5\n",
      "input_shape:   (224, 224, 3)\n",
      "batch_size:    2\n"
     ]
    }
   ],
   "source": [
    "gen_params.update(data_path='data.h5', \n",
    "                  inputs=['filename'],\n",
    "                  batch_size=2)\n",
    "gen.pretty(gen_params)\n",
    "g = gr.DataGeneratorHDF5(ids, **gen_params)\n",
    "assert gen.get_sizes(g[0]) == '([array<2,1>], [array<2,1>])'\n",
    "\n",
    "g.inputs_df = ['score', 'score']\n",
    "g.inputs = []\n",
    "g.outputs = []\n",
    "assert gen.get_sizes(g[0]) == '([array<2,2>], [])'\n",
    "\n",
    "g.inputs_df = [['score'], ('score','score')]\n",
    "assert gen.get_sizes(g[0]) == '([array<2,1>, array<2,2>], [])'\n",
    "\n",
    "g.inputs_df = []\n",
    "g.outputs = ['score']\n",
    "assert gen.get_sizes(g[0]) == '([], [array<2,1>])'\n",
    "\n",
    "g.outputs = ['score',['score']]\n",
    "with pytest.raises(AssertionError): g[0]\n",
    "\n",
    "g.outputs = [['score'],['score']]\n",
    "assert gen.get_sizes(g[0]) == '([], [array<2,1>, array<2,1>])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'features': [1, 2, 3, 4, 5], 'mask': [1, 0, 1, 1, 0]}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "def filter_features(df):\n",
    "    return np.array(df.loc[df['mask']==1,['features']])\n",
    "\n",
    "gen_params.update(data_path = None, \n",
    "                  outputs   = filter_features,\n",
    "                  inputs    = [],\n",
    "                  inputs_df = ['features'],\n",
    "                  shuffle   = False,\n",
    "                  batch_size= 5)\n",
    "# gen.pretty(gen_params)\n",
    "\n",
    "g = gr.DataGeneratorHDF5(df, **gen_params)\n",
    "assert gen.get_sizes(g[0]) == '([array<5,1>], array<3,1>)'\n",
    "assert all(np.squeeze(g[0][0]) == np.arange(1,6))\n",
    "assert all(np.squeeze(g[0][1]) == [1,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux2 -- Python 2.7.16, pytest-4.6.2, py-1.8.0, pluggy-0.12.0 -- /opt/conda/envs/jupyter_env27/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /mnt/home/research/ku/tests\n",
      "collected 7 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "test_generators.py::test_correct_df_input \u001b[32mPASSED\u001b[0m\u001b[36m                         [ 14%]\u001b[0m\n",
      "test_generators.py::test_init_generator \u001b[32mPASSED\u001b[0m\u001b[36m                           [ 28%]\u001b[0m\n",
      "test_generators.py::test_get_sizes \u001b[32mPASSED\u001b[0m\u001b[36m                                [ 42%]\u001b[0m\n",
      "test_generators.py::test_DataGeneratorDisk \u001b[32mPASSED\u001b[0m\u001b[36m                        [ 57%]\u001b[0m\n",
      "test_generators.py::test_H5Reader_and_Writer \u001b[32mPASSED\u001b[0m\u001b[36m                      [ 71%]\u001b[0m\n",
      "test_generators.py::test_DataGeneratorHDF5 \u001b[32mPASSED\u001b[0m\u001b[36m                        [ 85%]\u001b[0m\n",
      "test_generators.py::test_DataGeneratorHDF5_callable_outputs \u001b[32mPASSED\u001b[0m\u001b[36m       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 7 passed in 1.98 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter_env27]",
   "language": "python",
   "name": "conda-env-jupyter_env27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
