{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded keras utilities\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from ku import generators as gr\n",
    "from ku import generic as gen\n",
    "from ku import image_utils as iu\n",
    "from munch import Munch\n",
    "import pandas as pd, numpy as np\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_params = Munch(batch_size    = 2,\n",
    "                   data_path     = 'images',\n",
    "                   input_shape   = (224,224,3),\n",
    "                   inputs        = ['filename'],\n",
    "                   outputs       = ['score'],\n",
    "                   shuffle       = False,\n",
    "                   fixed_batches = True)\n",
    "\n",
    "ids = pd.read_csv(u'ids.csv', encoding='latin-1')\n",
    "\n",
    "np.all(ids.columns == ['filename', 'score'])\n",
    "np.all(ids.score == range(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.DataGeneratorDisk(ids, **gen_params)\n",
    "print(isinstance(g[0][1], list))\n",
    "print(np.all(g[0][1][0] == np.array([[1],[2]])))\n",
    "\n",
    "gen.get_sizes(g[0])=='([array<2,224,224,3>], [array<2,1>])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_fn = lambda p: iu.resize_image(iu.read_image(p), (100,100))\n",
    "g = gr.DataGeneratorDisk(ids, read_fn=read_fn, **gen_params)\n",
    "gen.get_sizes(g[0]) =='([array<2,100,100,3>], [array<2,1>])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([array<3,1>], <1>, [<1>, <1>])\n",
      "array<1,2>\n",
      "([<1>])\n"
     ]
    }
   ],
   "source": [
    "# reload(gen)\n",
    "x = np.array([[1,2,3]])\n",
    "print(gen.get_sizes(([x.T],1,[4,5])))\n",
    "y = np.array([[1,[1,2]]])\n",
    "print(gen.get_sizes(y))\n",
    "z = [g[0],([2],)]\n",
    "print(gen.get_sizes(z[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_params.inputs = ['filename', 'filename']\n",
    "g = gr.DataGeneratorDisk(ids, **gen_params)\n",
    "assert gen.get_sizes(g[0]) == '([array<2,224,224,3>, array<2,224,224,3>], [array<2,1>])'\n",
    "\n",
    "g.inputs_df = ['score', 'score']\n",
    "g.inputs = []\n",
    "g.outputs = []\n",
    "gen.get_sizes(g[0])\n",
    "\n",
    "g.inputs_df = [['score'], ('score','score')]\n",
    "assert gen.get_sizes(g[0]) == '([array<2,1>, array<2,2>], [])'\n",
    "\n",
    "g.inputs_df = []\n",
    "g.outputs = ['score']\n",
    "assert gen.get_sizes(g[0]) == '([], [array<2,1>])'\n",
    "\n",
    "g.outputs = ['score',['score']]\n",
    "with pytest.raises(AssertionError): g[0]\n",
    "\n",
    "g.outputs = [['score'],['score']]\n",
    "assert gen.get_sizes(g[0]) == '([], [array<2,1>, array<2,1>])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gen.H5Helper('data.h5', over_write=True) as h:\n",
    "    data = np.expand_dims(np.array(ids.score), 1)\n",
    "    h.write_data(data, list(ids.filename))\n",
    "\n",
    "with gen.H5Helper('data.h5', 'r') as h:\n",
    "    data = h.read_data(list(ids.filename))\n",
    "    assert all(data == np.array([[1],[2],[3],[4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size:    2\n",
      "data_path:     data.h5\n",
      "input_shape:   (224, 224, 3)\n",
      "inputs:        ['filename']\n",
      "outputs:       ['score']\n",
      "shuffle:       False\n",
      "fixed_batches: True\n"
     ]
    }
   ],
   "source": [
    "gen_params.update(data_path='data.h5', \n",
    "                  inputs=['filename'],\n",
    "                  batch_size=2)\n",
    "gen.pretty(gen_params)\n",
    "g = gr.DataGeneratorHDF5(ids, **gen_params)\n",
    "assert gen.get_sizes(g[0]) == '([array<2,1>], [array<2,1>])'\n",
    "\n",
    "g.inputs_df = ['score', 'score']\n",
    "g.inputs = []\n",
    "g.outputs = []\n",
    "assert gen.get_sizes(g[0]) == '([array<2,2>], [])'\n",
    "\n",
    "g.inputs_df = [['score'], ('score','score')]\n",
    "assert gen.get_sizes(g[0]) == '([array<2,1>, array<2,2>], [])'\n",
    "\n",
    "g.inputs_df = []\n",
    "g.outputs = ['score']\n",
    "assert gen.get_sizes(g[0]) == '([], [array<2,1>])'\n",
    "\n",
    "g.outputs = ['score',['score']]\n",
    "with pytest.raises(AssertionError): g[0]\n",
    "\n",
    "g.outputs = [['score'],['score']]\n",
    "assert gen.get_sizes(g[0]) == '([], [array<2,1>, array<2,1>])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'features': [1, 2, 3, 4, 5], 'mask': [1, 0, 1, 1, 0]}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "def filter_features(df):\n",
    "    return np.array(df.loc[df['mask']==1,['features']])\n",
    "\n",
    "gen_params.update(data_path = None, \n",
    "                  outputs   = filter_features,\n",
    "                  inputs    = [],\n",
    "                  inputs_df = ['features'],\n",
    "                  shuffle   = False,\n",
    "                  batch_size= 5)\n",
    "# gen.pretty(gen_params)\n",
    "\n",
    "g = gr.DataGeneratorHDF5(df, **gen_params)\n",
    "assert gen.get_sizes(g[0]) == '([array<5,1>], array<3,1>)'\n",
    "assert all(np.squeeze(g[0][0]) == np.arange(1,6))\n",
    "assert all(np.squeeze(g[0][1]) == [1,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: pytest: not found\n"
     ]
    }
   ],
   "source": [
    "!pytest -v --verbosity 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter_env] *",
   "language": "python",
   "name": "conda-env-jupyter_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
