{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded keras utilities\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import unittest\n",
    "\n",
    "from ku import generators as gr\n",
    "from ku import generic as gen\n",
    "from munch import Munch\n",
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_params = Munch(batch_size    = 2,\n",
    "                   data_path     = 'images',\n",
    "                   input_shape   = (224,224,3),\n",
    "                   inputs        = ['filename'],\n",
    "                   outputs       = ['score'],\n",
    "                   shuffle       = False,\n",
    "                   fixed_batches = True)\n",
    "\n",
    "ids = pd.read_csv('ids.csv', encoding='latin-1')\n",
    "\n",
    "np.all(ids.columns == ['filename', 'score'])\n",
    "np.all(ids.score == range(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.DataGeneratorDisk(ids, **gen_params)\n",
    "print(isinstance(g[0][1], list))\n",
    "print(np.all(g[0][1][0] == np.array([[1],[2]])))\n",
    "\n",
    "gen.get_sizes(g[0])=='([array<2,224,224,3>], [array<2,1>])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([array<3,1>], <1>, [<1>, <1>])\n",
      "array<1,2>\n",
      "([<1>])\n"
     ]
    }
   ],
   "source": [
    "reload(gen)\n",
    "x = np.array([[1,2,3]])\n",
    "print(gen.get_sizes(([x.T],1,[4,5])))\n",
    "y = np.array([[1,[1,2]]])\n",
    "print(gen.get_sizes(y))\n",
    "z = [g[0],([2],)]\n",
    "print(gen.get_sizes(z[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_params.inputs = ['filename', 'filename']\n",
    "g = gr.DataGeneratorDisk(ids, **gen_params)\n",
    "assert gen.get_sizes(g[0]) == '([array<2,224,224,3>, array<2,224,224,3>], [array<2,1>])'\n",
    "\n",
    "g.inputs_df = ['score', 'score']\n",
    "g.inputs = []\n",
    "g.outputs = []\n",
    "gen.get_sizes(g[0])\n",
    "\n",
    "g.inputs_df = [['score'], ('score','score')]\n",
    "assert gen.get_sizes(g[0]) == '([array<2,1>, array<2,2>], [])'\n",
    "\n",
    "# gen.pretty(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter_env27]",
   "language": "python",
   "name": "conda-env-jupyter_env27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
