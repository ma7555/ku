{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from ku import generators as gr\n",
    "from ku import generic as gen\n",
    "from ku import image_utils as iu\n",
    "from munch import Munch\n",
    "import pandas as pd, numpy as np\n",
    "import pytest\n",
    "from ku import image_augmenter as aug\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_params = Munch(batch_size    = 2,\n",
    "                   data_path     = 'images',\n",
    "                   input_shape   = (224,224,3),\n",
    "                   inputs        = ['filename'],\n",
    "                   outputs       = ['score'],\n",
    "                   shuffle       = False,\n",
    "                   fixed_batches = True)\n",
    "\n",
    "ids = pd.read_csv(u'ids.csv', encoding='latin-1')\n",
    "\n",
    "np.all(ids.columns == ['filename', 'score'])\n",
    "np.all(ids.score == range(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(im, arg):\n",
    "    return np.zeros(1) + arg\n",
    "\n",
    "gen_params_local = gen_params.copy()\n",
    "gen_params_local.process_fn = preproc\n",
    "gen_params_local.process_args  = {'filename': 'filename_args'}\n",
    "gen_params_local.batch_size = 4\n",
    "\n",
    "ids_local = ids.copy()\n",
    "ids_local['filename_args'] = range(len(ids_local))\n",
    "\n",
    "g = gr.DataGeneratorDisk(ids_local, **gen_params_local)\n",
    "x = g[0][0]\n",
    "assert np.array_equal(np.squeeze(x[0].T), np.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gr.DataGeneratorDisk(ids, **gen_params)\n",
    "print(isinstance(g[0][1], list))\n",
    "print(np.all(g[0][1][0] == np.array([[1],[2]])))\n",
    "\n",
    "gen.get_sizes(g[0])=='([array<2,224,224,3>], [array<2,1>])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_fn = lambda p: iu.resize_image(iu.read_image(p), (100,100))\n",
    "g = gr.DataGeneratorDisk(ids, read_fn=read_fn, **gen_params)\n",
    "gen.get_sizes(g[0]) =='([array<2,100,100,3>], [array<2,1>])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(gen)\n",
    "x = np.array([[1,2,3]])\n",
    "print(gen.get_sizes(([x.T],1,[4,5])))\n",
    "y = np.array([[1,[1,2]]])\n",
    "print(gen.get_sizes(y))\n",
    "z = [g[0],([2],)]\n",
    "print(gen.get_sizes(z[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_params.inputs = ['filename', 'filename']\n",
    "g = gr.DataGeneratorDisk(ids, **gen_params)\n",
    "assert gen.get_sizes(g[0]) == '([array<2,224,224,3>, array<2,224,224,3>], [array<2,1>])'\n",
    "\n",
    "g.inputs_df = ['score', 'score']\n",
    "g.inputs = []\n",
    "g.outputs = []\n",
    "gen.get_sizes(g[0])\n",
    "\n",
    "g.inputs_df = [['score'], ('score','score')]\n",
    "assert gen.get_sizes(g[0]) == '([array<2,1>, array<2,2>], [])'\n",
    "\n",
    "g.inputs_df = []\n",
    "g.outputs = ['score']\n",
    "assert gen.get_sizes(g[0]) == '([], [array<2,1>])'\n",
    "\n",
    "g.outputs = ['score',['score']]\n",
    "with pytest.raises(AssertionError): g[0]\n",
    "\n",
    "g.outputs = [['score'],['score']]\n",
    "assert gen.get_sizes(g[0]) == '([], [array<2,1>, array<2,1>])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gen.H5Helper('data.h5', over_write=True) as h:\n",
    "    data = np.expand_dims(np.array(ids.score), 1)\n",
    "    h.write_data(data, list(ids.filename))\n",
    "\n",
    "with gen.H5Helper('data.h5', 'r') as h:\n",
    "    data = h.read_data(list(ids.filename))\n",
    "    assert all(data == np.array([[1],[2],[3],[4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_params.update(data_path='data.h5', \n",
    "                  inputs=['filename'],\n",
    "                  batch_size=2)\n",
    "gen.pretty(gen_params)\n",
    "g = gr.DataGeneratorHDF5(ids, **gen_params)\n",
    "assert gen.get_sizes(g[0]) == '([array<2,1>], [array<2,1>])'\n",
    "\n",
    "g.inputs_df = ['score', 'score']\n",
    "g.inputs = []\n",
    "g.outputs = []\n",
    "assert gen.get_sizes(g[0]) == '([array<2,2>], [])'\n",
    "\n",
    "g.inputs_df = [['score'], ('score','score')]\n",
    "assert gen.get_sizes(g[0]) == '([array<2,1>, array<2,2>], [])'\n",
    "\n",
    "g.inputs_df = []\n",
    "g.outputs = ['score']\n",
    "assert gen.get_sizes(g[0]) == '([], [array<2,1>])'\n",
    "\n",
    "g.outputs = ['score',['score']]\n",
    "with pytest.raises(AssertionError): g[0]\n",
    "\n",
    "g.outputs = [['score'],['score']]\n",
    "assert gen.get_sizes(g[0]) == '([], [array<2,1>, array<2,1>])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'features': [1, 2, 3, 4, 5], 'mask': [1, 0, 1, 1, 0]}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "def filter_features(df):\n",
    "    return np.array(df.loc[df['mask']==1,['features']])\n",
    "\n",
    "gen_params.update(data_path = None, \n",
    "                  outputs   = filter_features,\n",
    "                  inputs    = [],\n",
    "                  inputs_df = ['features'],\n",
    "                  shuffle   = False,\n",
    "                  batch_size= 5)\n",
    "# gen.pretty(gen_params)\n",
    "\n",
    "g = gr.DataGeneratorHDF5(df, **gen_params)\n",
    "assert gen.get_sizes(g[0]) == '([array<5,1>], array<3,1>)'\n",
    "assert all(np.squeeze(g[0][0]) == np.arange(1,6))\n",
    "assert all(np.squeeze(g[0][1]) == [1,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.zeros((5,5,3))\n",
    "c = np.zeros((5,5,3))\n",
    "c[1:4,1:4,:] = 1\n",
    "\n",
    "assert np.array_equal(aug.cropout_patch(m, patch_size=(3,3), patch_position=(0.5,0.5), fill_val=1), c)\n",
    "\n",
    "m = np.zeros((256,256,3))\n",
    "plt.imshow(aug.cropout_random_patch(m.copy(), patch_size=(128,128), fill_val=1))\n",
    "plt.show()\n",
    "plt.imshow(aug.cropout_random_patch(m.copy(), patch_size=(128,128), fill_val=1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ku import image_utils as iu\n",
    "assert isinstance(iu.ImageAugmenter(np.ones(1)), aug.ImageAugmenter)\n",
    "\n",
    "m = np.zeros((5,5,3))\n",
    "c = np.zeros((5,5,3))\n",
    "c[1:4,1:4,:] = 1\n",
    "\n",
    "assert np.array_equal(aug.cropout_patch(m, patch_size=(3,3), patch_position=(0.5,0.5), fill_val=1), c)\n",
    "assert np.array_equal(aug.ImageAugmenter(c).cropout((3,3), crop_pos=(0.5,0.5), fill_val=1).result, c)\n",
    "assert np.array_equal(aug.ImageAugmenter(c).cropout((3,3), crop_pos=(0.5,0.5), fill_val=0).result, m)\n",
    "\n",
    "assert np.array_equal(aug.ImageAugmenter(c).crop((3,3), crop_pos=(0.5,0.5)).result, np.ones((3,3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.zeros((5,5,3))\n",
    "ml, mr = [m]*2\n",
    "ml[0:2,0:2,:] = 1\n",
    "mr[0:2,-2:,:] = 1\n",
    "\n",
    "assert np.array_equal(iu.ImageAugmenter(m).fliplr().result, m)\n",
    "assert np.array_equal(iu.ImageAugmenter(ml).fliplr().result, mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(gr)\n",
    "\n",
    "def preproc(im, *arg):\n",
    "    if arg:\n",
    "        return np.zeros(im.shape) + arg\n",
    "    else:\n",
    "        return im\n",
    "\n",
    "gen_params_local = gen_params.copy()\n",
    "gen_params_local.update(process_fn = preproc,\n",
    "                        data_path = 'data.h5', \n",
    "                        inputs    = ['filename', 'filename1'],\n",
    "                        process_args = {'filename' :'args'},\n",
    "                        batch_size = 4,\n",
    "                        shuffle    = False)\n",
    "\n",
    "ids_local = ids.copy()\n",
    "ids_local['filename1'] = ids_local['filename']\n",
    "ids_local['args'] = range(len(ids_local))\n",
    "ids_local['args1'] = range(len(ids_local),0,-1)\n",
    "\n",
    "g = gr.DataGeneratorHDF5(ids_local, **gen_params_local)\n",
    "\n",
    "assert np.array_equal(np.squeeze(g[0][0][0]), np.arange(4))\n",
    "assert np.array_equal(np.squeeze(g[0][0][1]), np.arange(1,5))\n",
    "assert np.array_equal(np.squeeze(g[0][1]), np.arange(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # l = [[1,4,7],[2,5,8],[3,6,9]]\n",
    "# l = [[1],[2],[3]]\n",
    "# l = zip(*l)\n",
    "# print(\"l:\", l)\n",
    "# l_a = map(np.stack, l)\n",
    "# print(\"l_a:\", l_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stack, convert float32] elapsed: 0.0821 seconds\n",
      "[iterate, init float32] elapsed: 0.1607 seconds\n",
      "<1000,100000>\n",
      "<1000,100000>\n"
     ]
    }
   ],
   "source": [
    "# np.stack is much faster on float32, and still faster for float16 data\n",
    "data_elem = np.arange(100000, dtype=np.float32)\n",
    "data = [data_elem.copy() for i in range(1000)]\n",
    "# gen.print_sizes(data)\n",
    "\n",
    "with gen.Timer('stack, convert float32'):\n",
    "    data_new_stack = np.float32(np.stack(data))\n",
    "\n",
    "with gen.Timer('iterate, init float32'):\n",
    "    data_new = None\n",
    "    for i, d in enumerate(data):\n",
    "        if data_new is None:\n",
    "            data_new = np.zeros((len(data),)+d.shape, dtype=np.float32)\n",
    "        data_new[i, ...] = d\n",
    "\n",
    "assert np.array_equal(data_new, data_new_stack)\n",
    "gen.print_sizes(data_new)\n",
    "gen.print_sizes(data_new_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([<2,224,224,3>, <2,224,224,3>], [<2,1>])\n"
     ]
    }
   ],
   "source": [
    "reload(gr)\n",
    "\n",
    "gen_params_ = gen_params.copy()\n",
    "gen_params_.process_fn = lambda im: [im, im+1]\n",
    "\n",
    "g = gr.DataGeneratorDisk(ids, **gen_params_)\n",
    "gen.print_sizes(g[0])\n",
    "assert np.array_equal(g[0][0][0], g[0][0][1]-1)\n",
    "assert np.array_equal(g[0][1][0], np.array([[1],[2]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter_env27]",
   "language": "python",
   "name": "conda-env-jupyter_env27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
